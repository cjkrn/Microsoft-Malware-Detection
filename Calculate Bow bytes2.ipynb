{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2022-06-09 13:28:01 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(u'nbAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from multiprocessing import Process# this is used for multithreading\n",
    "import multiprocessing\n",
    "import codecs# this is used for file operations \n",
    "import random as r\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "import joblib\n",
    "# get execution time for every cell DONT SHOW IT, AS IT COULD MESS PLOTS BEING DISPLAYED\n",
    "%load_ext autotime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01IsoiSMh5gxyDYTl4CB.txt',\n",
       " '02MRILoE6rNhmt7FUi45.txt',\n",
       " '04QzZ3DVdPsEp9elLR65.txt',\n",
       " '065EZhxgbLRSHsB87uIF.txt',\n",
       " '07nrG1cLKUPxjOlWMFiV.txt',\n",
       " '0AguvpOCcaf2myVDYFGb.txt',\n",
       " '0aVNj3qFgEZI6Akf4Kuv.txt',\n",
       " '0bjN3Kgw5OATSreRmEdi.txt',\n",
       " '0cfGJLYgE6ROaZH7KT1h.txt',\n",
       " '0cTu2bkefOAJqIhYUWFK.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('b2/')\n",
    "files[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2022-06-09 18:03:38 +05:30)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder = 1 and length 1359\n",
      "Folder = 2 and length 1359\n",
      "Folder = 3 and length 1359\n",
      "Folder = 4 and length 1359\n",
      "Folder = 5 and length 1358\n",
      "Folder = 6 and length 1358\n",
      "Folder = 7 and length 1358\n",
      "Folder = 8 and length 1358\n"
     ]
    }
   ],
   "source": [
    "# No of byte files per folder\n",
    "for folder in range(1,9):\n",
    "    f = os.listdir('b'+str(folder)+'/')\n",
    "    print(f'Folder = {folder} and length {len(f)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66049\n"
     ]
    }
   ],
   "source": [
    "# Applying the Multiprocessing method of ASM Files as Countvectorizer needs all the files in RAM and I have only 8gb RAM \n",
    "# Getting Bi-gram vocab\n",
    "\n",
    "vocab= \"00,01,02,03,04,05,06,07,08,09,0a,0b,0c,0d,0e,0f,10,11,12,13,14,15,16,17,18,19,1a,1b,1c,1d,1e,1f,20,21,22,23,24,25,26,27,28,29,2a,2b,2c,2d,2e,2f,30,31,32,33,34,35,36,37,38,39,3a,3b,3c,3d,3e,3f,40,41,42,43,44,45,46,47,48,49,4a,4b,4c,4d,4e,4f,50,51,52,53,54,55,56,57,58,59,5a,5b,5c,5d,5e,5f,60,61,62,63,64,65,66,67,68,69,6a,6b,6c,6d,6e,6f,70,71,72,73,74,75,76,77,78,79,7a,7b,7c,7d,7e,7f,80,81,82,83,84,85,86,87,88,89,8a,8b,8c,8d,8e,8f,90,91,92,93,94,95,96,97,98,99,9a,9b,9c,9d,9e,9f,a0,a1,a2,a3,a4,a5,a6,a7,a8,a9,aa,ab,ac,ad,ae,af,b0,b1,b2,b3,b4,b5,b6,b7,b8,b9,ba,bb,bc,bd,be,bf,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9,ca,cb,cc,cd,ce,cf,d0,d1,d2,d3,d4,d5,d6,d7,d8,d9,da,db,dc,dd,de,df,e0,e1,e2,e3,e4,e5,e6,e7,e8,e9,ea,eb,ec,ed,ee,ef,f0,f1,f2,f3,f4,f5,f6,f7,f8,f9,fa,fb,fc,fd,fe,ff,??\"\n",
    "    \n",
    "bi_gram_vocab=[]\n",
    "for index, hex in enumerate(vocab.split(',')):\n",
    "    for j in vocab.split(\",\"):\n",
    "        bi_gram_vocab.append(hex+' '+ j)\n",
    "print(len(bi_gram_vocab))\n",
    "\n",
    "# # Converting it into a dask delayed object\n",
    "# bigram_dict={}\n",
    "# for index, hex in enumerate(bi_gram_vocab):\n",
    "#     bigram_dict[hex]= index    \n",
    "# print(bigram_dict['00 00'])\n",
    "# print(len(bigram_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOING IT THE MULTIPROCESSING WAY\n",
    "\n",
    "# First 4 have 1359 byte files each and last 4 have 1358 files each\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def f1():\n",
    "    print('Starting and running process no 1')\n",
    "    vect = CountVectorizer(lowercase=False,vocabulary=bi_gram_vocab ,ngram_range=(2,2))\n",
    "    b1_matrix = csr_matrix((1359,len(bi_gram_vocab)))\n",
    "    \n",
    "    for i,file in tqdm(enumerate(os.listdir('b1/'))):\n",
    "        f = open('b1/' + file)\n",
    "        b1_matrix[i,:] += csr_matrix(vect.fit_transform([f.read().replace('\\n',' ').lower()]))\n",
    "        f.close()\n",
    "\n",
    "    # Making a matrix and making it the column of b1_data dataframe \n",
    "    b1_matrix = b1_matrix.todense()\n",
    "    b1_data = pd.DataFrame(b1_matrix,columns=bi_gram_vocab)\n",
    "    b1_data['ID'] = os.listdir('b1/')\n",
    "    b1_data.to_pickle('b1_data.pkl')\n",
    "    # with open('/content/gdrive/My Drive/Assignments AAIC/Assignment 16 Malware/Final/bytes/b1_data', 'wb') as files:\n",
    "    #     joblib.dump(b1_data, files)\n",
    "    \n",
    "    \n",
    "def f2():\n",
    "    print('Starting and running process no 2')\n",
    "    vect = CountVectorizer(lowercase=False,vocabulary=bi_gram_vocab,ngram_range=(2,2))\n",
    "    b2_matrix = csr_matrix((1359,len(bi_gram_vocab)))\n",
    "    \n",
    "    for i,file in tqdm(enumerate(os.listdir('b2/'))):\n",
    "        f = open('b2/' + file)\n",
    "        b2_matrix[i,:] += csr_matrix(vect.fit_transform([f.read().replace('\\n',' ').lower()]))\n",
    "        f.close()\n",
    "        \n",
    "    b2_matrix = b2_matrix.todense()\n",
    "    b2_data = pd.DataFrame(b2_matrix,columns=bi_gram_vocab)\n",
    "    b2_data['ID'] = os.listdir('b2/')\n",
    "    b2_data.to_pickle('b2_data.pkl')\n",
    "    # with open('/content/gdrive/My Drive/Assignments AAIC/Assignment 16 Malware/Final/bytes/b2_data', 'wb') as files:\n",
    "    #     joblib.dump(b2_data, files)\n",
    "\n",
    "def f3():\n",
    "    print('Starting and running process no 3')\n",
    "    vect = CountVectorizer(lowercase=False,vocabulary=bi_gram_vocab,ngram_range=(2,2))\n",
    "    b3_matrix = csr_matrix((1359,len(bi_gram_vocab)))\n",
    "    \n",
    "    for i,file in tqdm(enumerate(os.listdir('b3/'))):\n",
    "        f = open('b3/' + file)\n",
    "        b3_matrix[i,:] += csr_matrix(vect.fit_transform([f.read().replace('\\n',' ').lower()]))\n",
    "        f.close()\n",
    "        \n",
    "    b3_matrix = b3_matrix.todense()\n",
    "    b3_data = pd.DataFrame(b3_matrix,columns=bi_gram_vocab)\n",
    "    b3_data['ID'] = os.listdir('b3/')\n",
    "    b3_data.to_pickle('b3_data.pkl')\n",
    "    # with open('/content/gdrive/My Drive/Assignments AAIC/Assignment 16 Malware/Final/bytes/b3_data', 'wb') as files:\n",
    "    #     joblib.dump(b3_data, files)\n",
    "    \n",
    "def f4():\n",
    "    print('Starting and running process no 4')\n",
    "    vect = CountVectorizer(lowercase=False,vocabulary=bi_gram_vocab,ngram_range=(2,2))\n",
    "    b4_matrix = csr_matrix((1359,len(bi_gram_vocab)))\n",
    "    \n",
    "    for i,file in tqdm(enumerate(os.listdir('b4/'))):\n",
    "        f = open('b4/' + file)\n",
    "        b4_matrix[i,:] += csr_matrix(vect.fit_transform([f.read().replace('\\n',' ').lower()]))\n",
    "        f.close()\n",
    "        \n",
    "    b4_matrix = b4_matrix.todense()\n",
    "    b4_data = pd.DataFrame(b4_matrix,columns=bi_gram_vocab)\n",
    "    b4_data['ID'] = os.listdir('b4/')\n",
    "    b4_data.to_pickle('b4_data.pkl')\n",
    "    # with open('/content/gdrive/My Drive/Assignments AAIC/Assignment 16 Malware/Final/bytes/b4_data', 'wb') as files:\n",
    "    #     joblib.dump(b4_data, files)\n",
    "    \n",
    "    \n",
    "def f5():\n",
    "    print('Starting and running process no 5')\n",
    "    vect = CountVectorizer(lowercase=False,vocabulary=bi_gram_vocab,ngram_range=(2,2))\n",
    "    b5_matrix = csr_matrix((1358,len(bi_gram_vocab)))\n",
    "    \n",
    "    for i,file in tqdm(enumerate(os.listdir('b5/'))):\n",
    "        f = open('b5/' + file)\n",
    "        b5_matrix[i,:] += csr_matrix(vect.fit_transform([f.read().replace('\\n',' ').lower()]))\n",
    "        f.close()\n",
    "        \n",
    "    b5_matrix = b5_matrix.todense()\n",
    "    b5_data = pd.DataFrame(b5_matrix,columns=bi_gram_vocab)\n",
    "    b5_data['ID'] = os.listdir('b5/')\n",
    "    b5_data.to_pickle('b5_data.pkl')\n",
    "    # with open('/content/gdrive/My Drive/Assignments AAIC/Assignment 16 Malware/Final/bytes/b5_data', 'wb') as files:\n",
    "    #     joblib.dump(b5_data, files)\n",
    "    \n",
    "def f6():\n",
    "    print('Starting and running process no 6')\n",
    "    vect = CountVectorizer(lowercase=False,vocabulary=bi_gram_vocab,ngram_range=(2,2))\n",
    "    b6_matrix = csr_matrix((1358,len(bi_gram_vocab)))\n",
    "    \n",
    "    for i,file in tqdm(enumerate(os.listdir('b6/'))):\n",
    "        f = open('b6/' + file)\n",
    "        b6_matrix[i,:] += csr_matrix(vect.fit_transform([f.read().replace('\\n',' ').lower()]))\n",
    "        f.close()\n",
    "        \n",
    "    b6_matrix = b6_matrix.todense()\n",
    "    b6_data = pd.DataFrame(b6_matrix,columns=bi_gram_vocab)\n",
    "    b6_data['ID'] = os.listdir('b6/')\n",
    "    b6_data.to_pickle('b6_data.pkl')\n",
    "    # with open('/content/gdrive/My Drive/Assignments AAIC/Assignment 16 Malware/Final/bytes/b6_data', 'wb') as files:\n",
    "    #     joblib.dump(b6_data, files)\n",
    "    \n",
    "def f7():\n",
    "    print('Starting and running process no 7')\n",
    "    vect = CountVectorizer(lowercase=False,vocabulary=bi_gram_vocab,ngram_range=(2,2))\n",
    "    b7_matrix = csr_matrix((1358,len(bi_gram_vocab)))\n",
    "    \n",
    "    for i,file in tqdm(enumerate(os.listdir('b7/'))):\n",
    "        f = open('b7/' + file)\n",
    "        b7_matrix[i,:] += csr_matrix(vect.fit_transform([f.read().replace('\\n',' ').lower()]))\n",
    "        f.close()\n",
    "        \n",
    "    b7_matrix = b7_matrix.todense()\n",
    "    b7_data = pd.DataFrame(b7_matrix,columns=bi_gram_vocab)\n",
    "    b7_data['ID'] = os.listdir('b7/')\n",
    "    b7_data.to_pickle('b7_data.pkl')\n",
    "    # with open('/content/gdrive/My Drive/Assignments AAIC/Assignment 16 Malware/Final/bytes/b7_data', 'wb') as files:\n",
    "    #     joblib.dump(b7_data, files)\n",
    "\n",
    "def f8():\n",
    "    print('Starting and running process no 8')\n",
    "    vect = CountVectorizer(lowercase=False,vocabulary=bi_gram_vocab,ngram_range=(2,2))\n",
    "    b8_matrix = csr_matrix((1358,len(bi_gram_vocab)))\n",
    "    \n",
    "    for i,file in tqdm(enumerate(os.listdir('b8/'))):\n",
    "        f = open('b8/' + file)\n",
    "        b8_matrix[i,:] += csr_matrix(vect.fit_transform([f.read().replace('\\n',' ').lower()]))\n",
    "        f.close()\n",
    "        \n",
    "    b8_matrix = b8_matrix.todense()\n",
    "    b8_data = pd.DataFrame(b8_matrix,columns=bi_gram_vocab)\n",
    "    b8_data['ID'] = os.listdir('b8/')\n",
    "    b8_data.to_pickle('b8_data.pkl')\n",
    "    # with open('/content/gdrive/My Drive/Assignments AAIC/Assignment 16 Malware/Final/bytes/b8_data', 'wb') as files:\n",
    "    #     joblib.dump(b8_data, files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting and running process no 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1359it [49:37,  2.19s/it]\n"
     ]
    }
   ],
   "source": [
    "f2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166e701",
   "metadata": {},
   "source": [
    "## Steps to convert files into images:-\n",
    "## 1. Find First 800 Pixels as the Kaggle Winners found it to be the best through CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 399.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/Applied Ai Course/Assignments/Assgn 16 Malware Detection/asm5a/\n",
      "d:/Applied Ai Course/Assignments/Assgn 16 Malware Detection/asm5b/\n",
      "d:/Applied Ai Course/Assignments/Assgn 16 Malware Detection/asm5c/\n",
      "d:/Applied Ai Course/Assignments/Assgn 16 Malware Detection/asm5d/\n",
      "d:/Applied Ai Course/Assignments/Assgn 16 Malware Detection/asm5e/\n",
      "d:/Applied Ai Course/Assignments/Assgn 16 Malware Detection/asm5f/\n",
      "d:/Applied Ai Course/Assignments/Assgn 16 Malware Detection/asm5g/\n",
      "d:/Applied Ai Course/Assignments/Assgn 16 Malware Detection/asm5h/\n",
      "time: 78 ms (started: 2022-06-09 15:48:28 +05:30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files=['a','b','c','d','e','f','g','h']\n",
    "# Create Images and store it in asm_image folder \n",
    "for sub_folder in tqdm(files):    \n",
    "    newpath= 'd:/Applied Ai Course/Assignments/Assgn 16 Malware Detection/' \n",
    "    if not os.path.exists(newpath+ 'asm5' + sub_folder):\n",
    "        print(newpath+ 'asm5' + sub_folder + '/')\n",
    "        os.makedirs(newpath + 'asm5' + sub_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# No of byte files per folder\n",
    "for folder in range(1,9):\n",
    "    f = os.listdir('asm'+str(folder)+'/')\n",
    "    print(f'Folder = {folder} and length {len(f)}')\n",
    "\n",
    "# https://www.sharpsightlabs.com/blog/skimage-imread/\n",
    "import array\n",
    "import io \n",
    "import cv2\n",
    "\n",
    "pwd\n",
    "\n",
    "asmfiles= os.listdir(\"asm1\")\n",
    "asmfiles[:5]\n",
    "\n",
    "<h2> Example for creation of Image from ASM Text File stored in Final Folder\n",
    "\n",
    "# https://stackoverflow.com/questions/5250744/difference-between-open-and-codecs-open-in-python\n",
    "import io \n",
    "\n",
    "asmfile=\"0ACDbR5M3ZhBJajygTuf.asm\"\n",
    "file_name = asmfile.split('.')[0]\n",
    "# Open the ASM file \n",
    "file = io.open('asm1/'+asmfile,'rb') \n",
    "# Get it's size\n",
    "file_size = os.path.getsize('asm1/'+asmfile) \n",
    "print(file_size)\n",
    "\n",
    "# width = sqrt(file size) \n",
    "# So that we can make width * width ~ file size ie a square image with roughly same no of Pixels as file size\n",
    "width = int(file_size**0.5)\n",
    "print(width)\n",
    "rem = (file_size/width)\n",
    "print(rem)\n",
    "\n",
    "# 'B'  is for 8 bit values ie 0-255 value only allowed per array cell \n",
    "ar = array.array('B')\n",
    "print(type(ar))\n",
    "print(ar[:100])\n",
    "# https://stackoverflow.com/questions/55225542/how-to-create-an-image-from-a-string\n",
    "ar.frombytes(file.read()) # Create an image object\n",
    "print(len(ar))\n",
    "\n",
    "file.close()\n",
    "print(ar)\n",
    "reshaped = np.reshape(ar[:width * width], (width, width))  # creating the shape of image\n",
    "reshaped = np.uint8(reshaped)     \n",
    "# print(reshaped.shape)\n",
    "\n",
    "print(reshaped[:100])\n",
    "\n",
    "def asm_image(folder):\n",
    "    # https://stackoverflow.com/questions/5250744/difference-between-open-and-codecs-open-in-python\n",
    "    \n",
    "    for asm_file in tqdm(os.listdir(folder_name+'/')):\n",
    "        \n",
    "        file_name = asm_file.split('.')[0]\n",
    "        file = io.open(folder + '/'+ asm_file,'rb') \n",
    "        # Get it's size\n",
    "        file_size = os.path.getsize(folder_name+ '/'+asmfile) \n",
    "        width=0\n",
    "        # width = sqrt(file size) \n",
    "        # So that we can make width * width ~ file size ie a square image with roughly same no of Pixels as file size\n",
    "        width = int(file_size**0.5)\n",
    "        ar = array.array('B')\n",
    "        # https://stackoverflow.com/questions/55225542/how-to-create-an-image-from-a-string\n",
    "        ar.frombytes(file.read()) # Create an image object\n",
    "        file.close()\n",
    "\n",
    "        # creating the shape of image eg:- for one asm file:- ar[row : 7678 * 7678] reshaped to ar(7678,7678)\n",
    "        reshaped = np.reshape(ar[:width * width], (width, width))  \n",
    "        reshaped = np.uint8(reshaped)     \n",
    "        cv2.imwrite(folder_name + '/' + file_name + '.png',reshaped)\n",
    "        \n",
    "\n",
    "pwd\n",
    "\n",
    "%%time\n",
    "# Create Images and store it in asm_image folder \n",
    "for folder in range(1,9):\n",
    "    folder_name= 'asm'+ str(folder)\n",
    "    print(f'Processing Folder {folder_name}')\n",
    "    # asm_image(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 531 ms (started: 2022-06-09 18:04:10 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# https://www.sharpsightlabs.com/blog/skimage-imread/\n",
    "import array\n",
    "import io \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-06-09 18:05:09 +05:30)\n"
     ]
    }
   ],
   "source": [
    "asm_no=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6278974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-06-09 18:05:09 +05:30)\n"
     ]
    }
   ],
   "source": [
    "def asm_image(folder_name):\n",
    "    \n",
    "    # https://stackoverflow.com/questions/5250744/difference-between-open-and-codecs-open-in-python\n",
    "    for index, asm_file in tqdm(enumerate(os.listdir(folder_name))):\n",
    "        \n",
    "        file_name = asm_file.split('.')[0]\n",
    "        file = io.open(folder_name + asm_file,'rb') \n",
    "        file_stats = os.stat(folder_name+ asm_file)\n",
    "        # get file size in bytes and in int format\n",
    "        file_size= file_stats.st_size \n",
    "        \n",
    "        width=0\n",
    "        # width = sqrt(file size) \n",
    "        # So that we can make width * width ~ file size ie a square image with roughly same no of Pixels as file size\n",
    "        width = int(file_size**0.5)\n",
    "        ar = array.array('B')\n",
    "        # https://stackoverflow.com/questions/55225542/how-to-create-an-image-from-a-string\n",
    "        ar.frombytes(file.read()) # Create an image object\n",
    "        # if index<20:\n",
    "        #     print(\"Size of file :\",file_name)\n",
    "        #     print(f'File no {index} size {file_size} and width{width}')\n",
    "\n",
    "        # creating the shape of image eg:- for one asm file:- ar[row : 7678 * 7678] reshaped to ar(7678,7678)\n",
    "        reshaped = np.reshape(ar[:width * width], (width, width))  \n",
    "        reshaped = np.uint8(reshaped)     \n",
    "        \n",
    "        cv2.imwrite('d:/Applied Ai Course/Assignments/Assgn 16 Malware Detection/asm_images/' + file_name + '.png',reshaped)\n",
    "        file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ab6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [01:11,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 11s (started: 2022-06-09 12:44:03 +05:30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# folder_name= 'asm1/asm1a/'\n",
    "# asm_image(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder asm6/asm6a/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [01:48,  1.57it/s]\n",
      " 12%|█▎        | 1/8 [01:48<12:37, 108.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder asm6/asm6b/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [01:53,  1.50it/s]\n",
      " 25%|██▌       | 2/8 [03:41<11:06, 111.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder asm6/asm6c/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [01:22,  2.06it/s]\n",
      " 38%|███▊      | 3/8 [05:03<08:10, 98.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder asm6/asm6d/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [01:21,  2.09it/s]\n",
      " 50%|█████     | 4/8 [06:25<06:06, 91.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder asm6/asm6e/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [01:18,  2.17it/s]\n",
      " 62%|██████▎   | 5/8 [07:43<04:20, 86.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder asm6/asm6f/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [01:22,  2.06it/s]\n",
      " 75%|███████▌  | 6/8 [09:06<02:50, 85.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder asm6/asm6g/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [01:45,  1.60it/s]\n",
      " 88%|████████▊ | 7/8 [10:52<01:32, 92.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder asm6/asm6h/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [01:30,  1.88it/s]\n",
      "100%|██████████| 8/8 [12:22<00:00, 92.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12min 22s (started: 2022-06-09 18:05:14 +05:30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Steps to convert files into images:-\n",
    "## 1. Find First 800 Pixels as the Kaggle Winners found it to be the best through CV.\n",
    "\n",
    "# As I can't even fit 16gb Files (after dividing 120gb ASM Files into 8) in my ram so I'm dividing them again into 8 folders and then creating images\n",
    "# So my ram usage per asm folder is less than 2- 3gb\n",
    "files=['a','b','c','d','e','f','g','h']\n",
    "# Create Images and store it in asm_image folder \n",
    "for folder in tqdm(files):\n",
    "    # folder_name= 'asm4/asm4'+ str(folder) +'/'\n",
    "    folder_name= 'asm'+str(asm_no)+'/'+ 'asm' +str(asm_no)+ str(folder) +'/'\n",
    "    print(f'Processing Folder {folder_name}')\n",
    "    asm_image(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder asm/asm1a\n",
      "Processing Folder asm/asm1b\n",
      "Processing Folder asm/asm1c\n",
      "Processing Folder asm/asm1d\n",
      "Processing Folder asm/asm1e\n",
      "Processing Folder asm/asm1f\n",
      "Processing Folder asm/asm1g\n",
      "Processing Folder asm/asm1h\n",
      "time: 15 ms (started: 2022-06-09 10:07:30 +05:30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Steps to convert files into images:-\n",
    "## 1. Find First 800 Pixels as the Kaggle Winners found it to be the best through CV.\n",
    "files=['a','b','c','d','e','f','g','h']\n",
    "# Create Images and store it in asm_image folder \n",
    "for folder in tqdm(files):\n",
    "    folder_name= 'asm1/asm1'+ str(folder)\n",
    "    print(f'Processing Folder {folder_name}')\n",
    "    \n",
    "    asm_image(folder_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7a650a0512ab63a57e877f4b11948ac2343f5e7259e8b5d406ecff5191ba340"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('malware')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
